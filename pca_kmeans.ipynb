{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d743ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from scipy.interpolate import interp1d, griddata\n",
    "from sklearn.decomposition import PCA\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.core.periodic_table import Element\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_imports import *\n",
    "from utils import get_species, load_data, build_data, standardXAS, clusterXAS\n",
    "\n",
    "seed = 14\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d081e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors for scatter points\n",
    "cols = ['#6A71B4', '#F7B744']\n",
    "cmap = colors.ListedColormap(cols)\n",
    "\n",
    "# transparent colormaps for gaussians\n",
    "tmaps = [make_transparent_cmap(cols[0],0,0.6),\n",
    "         make_transparent_cmap(cols[1],0,0.6)]\n",
    "\n",
    "def gaussian(x, y, cx, cy, r):\n",
    "    return np.exp(-((x-cx)**2+(y-cy)**2)/(2*r*r))\n",
    "\n",
    "def smooth_data(x, window_radius):\n",
    "    window_len = 2*window_radius+1\n",
    "    w = np.hanning(window_len)\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-2:-window_len-1:-1]]\n",
    "    y = np.convolve(s, w/w.sum(), mode='valid')\n",
    "    return y[window_radius:x.shape[-1] + window_radius]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data_merged.csv'\n",
    "       \n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "num_classes = 2\n",
    "data, species = load_data(data_path, num_classes)\n",
    "\n",
    "# exclude select samples\n",
    "data_inc = data[data['tag'] == 'INC'].reset_index(drop=True)\n",
    "print('number of inconclusive samples:', len(data_inc))\n",
    "get_species(data_inc)\n",
    "\n",
    "data_weyl = data[data['tag'] == 'WEYL'].reset_index(drop=True)\n",
    "print('number of weyl semimetal samples:', len(data_weyl))\n",
    "get_species(data_weyl)\n",
    "\n",
    "data = data[data['tag'].isna()].reset_index(drop=True)\n",
    "print('number of train/valid/test samples:', len(data))\n",
    "\n",
    "species_data = get_species(data)\n",
    "\n",
    "n = 200 # number of energy bins\n",
    "nc = 20 # maximum number of principal components\n",
    "evar = 0.8 # minimum cumulative explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ad8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load computed train/valid/test split\n",
    "with open('data/idx_train.txt', 'r') as f:\n",
    "    idx_train = [int(i.split('\\n')[0]) for i in f.readlines()]\n",
    "\n",
    "with open('data/idx_valid.txt', 'r') as f:\n",
    "    idx_valid = [int(i.split('\\n')[0]) for i in f.readlines()]\n",
    "\n",
    "with open('data/idx_test.txt', 'r') as f:\n",
    "    idx_test = [int(i.split('\\n')[0]) for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_all = []\n",
    "for z in range(1,119):\n",
    "    species_all += [Element.from_Z(z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine validation and test sets into a single test set\n",
    "idx_test = np.hstack([idx_valid, idx_test])\n",
    "\n",
    "col = 'spectra_abs'\n",
    "x_train_tot, y_train_tot, e_train_tot, type_encoding = build_data(data, species_all, idx_train, col)\n",
    "x_test_tot, y_test_tot, e_test_tot, _ = build_data(data, species_all, idx_test, col)\n",
    "y_train_tot = y_train_tot.ravel()\n",
    "y_test_tot = y_test_tot.ravel()\n",
    "\n",
    "print('Training size:',len(x_train_tot))\n",
    "print('Testing size:',len(x_test_tot))\n",
    "\n",
    "# standardize data\n",
    "ne = x_train_tot.shape[-1]\n",
    "sdx = standardXAS(ne)\n",
    "sdx.fit_transform(x_train_tot, e_train_tot)\n",
    "sdx.transform(x_test_tot, e_test_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b329bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get periodic table data\n",
    "elem_data = dict(zip(['specie', 'row', 'column'], [[], [], []]))\n",
    "for i in range(1,119):\n",
    "    specie = Element.from_Z(i)\n",
    "    elem_data['specie'].append(str(specie))\n",
    "    \n",
    "    # put La and Ac in rows 6 and 7 for display\n",
    "    if str(specie) == 'La':\n",
    "        elem_data['row'].append(6)\n",
    "        elem_data['column'].append(specie.group)\n",
    "    elif str(specie) == 'Ac':\n",
    "        elem_data['row'].append(7)\n",
    "        elem_data['column'].append(specie.group)\n",
    "        \n",
    "    # shift the group of row 8 and row 9 by -1 for display\n",
    "    elif specie.row > 7:\n",
    "        elem_data['row'].append(specie.row)\n",
    "        elem_data['column'].append(specie.group - 1)\n",
    "    \n",
    "    else:\n",
    "        elem_data['row'].append(specie.row)\n",
    "        elem_data['column'].append(specie.group)\n",
    "    \n",
    "elem_data = pd.DataFrame(elem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc06054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot element-specific spectra by class\n",
    "nrow = 9\n",
    "ncol = 18\n",
    "\n",
    "prop.set_size(14)\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(2*ncol,2*nrow))\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        elem = elem_data.loc[(elem_data['row']==i+1) & (elem_data['column']==j+1), 'specie'].tolist()\n",
    "        \n",
    "        if len(elem):\n",
    "            # valid element\n",
    "            elem = elem[0]\n",
    "            k = type_encoding.index(elem)\n",
    "            ax[i,j].set_xticks([]); ax[i,j].set_yticks([])\n",
    "            \n",
    "            mask_train = e_train_tot[:,k].ravel() == 1\n",
    "            mask_test = e_test_tot[:,k].ravel() == 1\n",
    "            ncn = np.sum(mask_train).astype(int)\n",
    "            nct = np.sum(mask_test).astype(int)\n",
    "    \n",
    "            if ncn > 1:\n",
    "                # element in data\n",
    "                # initialize a numpy array for spectra\n",
    "                x_train = np.copy(x_train_tot[mask_train,:,k])\n",
    "                y_train = np.copy(y_train_tot[mask_train])\n",
    "                x_test = np.copy(x_test_tot[mask_test,:,k])\n",
    "                y_test = np.copy(y_test_tot[mask_test])\n",
    "                \n",
    "                x_data = np.vstack([x_train, x_test])\n",
    "                y_data = np.hstack([y_train, y_test])\n",
    "\n",
    "                for o in range(num_classes):\n",
    "                    if len(y_data[y_data==o]) > 0:\n",
    "                        xc = x_data[y_data==o,:]\n",
    "                        xc_mean = xc.mean(axis=0)\n",
    "                        xc_std = smooth_data(xc.std(axis=0), 11)\n",
    "                        ax[i,j].fill_between(range(n), xc_mean + xc_std, xc_mean - xc_std, color=cols[o],\n",
    "                                             alpha=0.4, lw=0)\n",
    "                        ax[i,j].plot(range(n), xc_mean, color=cols[o], lw=2, zorder=10000)\n",
    "\n",
    "                ax[i,j].text(0.1, 0.8, elem, color='black', fontproperties=prop, transform=ax[i,j].transAxes,\n",
    "                             zorder=500000)\n",
    "                \n",
    "            else:\n",
    "                # element not in data\n",
    "                ax[i,j].spines['bottom'].set_color('gray')\n",
    "                ax[i,j].spines['top'].set_color('gray') \n",
    "                ax[i,j].spines['right'].set_color('gray')\n",
    "                ax[i,j].spines['left'].set_color('gray')\n",
    "                ax[i,j].text(0.1, 0.8, elem, color='gray', fontproperties=prop, transform=ax[i,j].transAxes)\n",
    "\n",
    "        else:\n",
    "            # invalid element\n",
    "            ax[i,j].remove()\n",
    "            \n",
    "fig.savefig('images/periodic_table_spectra.png', bbox_inches='tight', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d40541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot element-specific pca and k-means clustering\n",
    "nrow = 9\n",
    "ncol = 18\n",
    "\n",
    "marker_size = 4\n",
    "prop.set_size(14)\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(2*ncol,2*nrow))\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        elem = elem_data.loc[(elem_data['row']==i+1) & (elem_data['column']==j+1), 'specie'].tolist()\n",
    "        \n",
    "        if len(elem):\n",
    "            # valid element\n",
    "            elem = elem[0]\n",
    "            k = type_encoding.index(elem)\n",
    "            ax[i,j].set_xticks([]); ax[i,j].set_yticks([])\n",
    "            \n",
    "            mask_train = e_train_tot[:,k].ravel() == 1\n",
    "            mask_test = e_test_tot[:,k].ravel() == 1\n",
    "            ncn = np.sum(mask_train).astype(int)\n",
    "            nct = np.sum(mask_test).astype(int)\n",
    "        \n",
    "            if ncn > 1:\n",
    "                # element in data\n",
    "                # initialize a numpy array for spectra\n",
    "                x_train = np.copy(x_train_tot[mask_train,:,k])\n",
    "                y_train = np.copy(y_train_tot[mask_train])\n",
    "                x_test = np.copy(x_test_tot[mask_test,:,k])\n",
    "                y_test = np.copy(y_test_tot[mask_test])\n",
    "                print(\"Train count: {:d} Test count: {:d}\".format(ncn, nct))\n",
    "\n",
    "                # perform PCA fit on training data, and transform all data\n",
    "                mnc = min(nc, ncn)\n",
    "                pca = PCA(n_components=mnc, svd_solver='full')\n",
    "                pca.fit(x_train)\n",
    "\n",
    "                # number of components to achieve target variance\n",
    "                try: mnc = list((pca.explained_variance_ratio_.cumsum() > evar).astype(int)).index(1) + 1\n",
    "                except: pass\n",
    "\n",
    "                if mnc < 2: mnc = 2 # minimum of 2 components\n",
    "                print(\"Retained {:.4f} explained variance with {:d} components.\".format(\n",
    "                    pca.explained_variance_ratio_[:mnc].cumsum()[-1],mnc))\n",
    "\n",
    "                # refit with optimal components\n",
    "                pca = PCA(n_components=mnc, svd_solver='full')\n",
    "                pca.fit(x_train)\n",
    "                p_train = pca.transform(x_train)\n",
    "\n",
    "                if nct > 0:\n",
    "                    p_test = pca.transform(x_test)\n",
    "                else: p_test = 0\n",
    "\n",
    "                # perform k-means clustering\n",
    "                clx = clusterXAS(n_clusters=2)\n",
    "                p_filter, y_filter = clx.remove_outliers(p_train, y_train, frac=0.98)\n",
    "                clx.fit(p_filter, y_filter)\n",
    "\n",
    "                # pca for visualization\n",
    "                pca_viz = PCA(n_components=2, svd_solver='full')\n",
    "                pca_viz.fit(p_train)\n",
    "                pv_train = pca_viz.transform(p_train)\n",
    "                pv_test = pca_viz.transform(p_test)\n",
    "\n",
    "                # predict on a grid\n",
    "                lim = 2*np.max(np.std(p_filter, axis=0))\n",
    "                x, y = np.meshgrid(np.linspace(-lim,lim,1000), np.linspace(-lim,lim,1000))\n",
    "                xh = pca_viz.inverse_transform(np.c_[x.ravel(), y.ravel()])\n",
    "                z = clx.predict(xh)\n",
    "                z = z.reshape(x.shape)\n",
    "\n",
    "                # predict on the cluster center locations\n",
    "                ct = clx.predict(clx.kmeans.cluster_centers_).astype(int)\n",
    "\n",
    "                # grid plot\n",
    "                ax[i,j].imshow(z, interpolation='nearest', extent=(x.min(), x.max(), y.min(), y.max()), cmap=cmap,\n",
    "                               alpha=0.15, aspect='auto', origin='lower', vmin=0, vmax=1)\n",
    "\n",
    "                # gaussian plots\n",
    "                centers = []\n",
    "                dists = np.zeros((pv_train.shape[0],2))\n",
    "                for c in range(2):\n",
    "                    cx, cy = pca_viz.transform(clx.kmeans.cluster_centers_[c,:].reshape(1,-1)).ravel()\n",
    "                    centers += [[cx,cy]]\n",
    "                    dists[:,c] = np.square(pv_train[:,0]-cx)+np.square(pv_train[:,1]-cy)\n",
    "                centers = np.array(centers)\n",
    "                clusters = np.argmin(dists, axis=1)\n",
    "                inertia = sum([dists[c,clusters[c]] for c in range(len(pv_train))])\n",
    "                for c in range(2):\n",
    "                    cx, cy = centers[c]\n",
    "                    r = np.sqrt(inertia/len(pv_train))\n",
    "                    ax[i,j].imshow(gaussian(x, y, cx, cy, r), interpolation='bicubic',\n",
    "                                   extent=(x.min(), x.max(), y.min(), y.max()), cmap=tmaps[ct[c]], aspect='auto',\n",
    "                                   origin='lower', vmin=0, vmax=1)\n",
    "\n",
    "                # data plot\n",
    "                # shift the data by the mean of the first value in the \n",
    "                # training set just to make it easier to plot consistently\n",
    "                mu = np.mean(x_train[:,0]); std = np.std(x_train[:,0])\n",
    "                x_test -= mu\n",
    "                x_train -= mu\n",
    "                for o in range(num_classes):\n",
    "                    for s,p,c in zip([x_train, x_test],\n",
    "                                     [pv_train, pv_test],\n",
    "                                     [y_train, y_test]):\n",
    "                        if len(c[c==o]) > 0:\n",
    "                            ax[i,j].scatter(p[:,0][c==o], p[:,1][c==o], color=cols[o], alpha=0.8, s=marker_size,\n",
    "                                            lw=0, zorder=10000)\n",
    "\n",
    "                # centers plot\n",
    "                for c in range(2):\n",
    "                    cx, cy = centers[c]\n",
    "                    ax[i,j].scatter(cx, cy, marker='x', color='w', s=2*marker_size, lw=0.5, zorder=30000)\n",
    "                  \n",
    "                \n",
    "                ax[i,j].set_xlim(-lim,lim)\n",
    "                ax[i,j].set_ylim(-lim,lim)\n",
    "                ax[i,j].text(0.1, 0.8, elem, color='black', fontproperties=prop, transform=ax[i,j].transAxes,\n",
    "                             zorder=500000)\n",
    "                \n",
    "            else:\n",
    "                # element not in data\n",
    "                ax[i,j].spines['bottom'].set_color('gray')\n",
    "                ax[i,j].spines['top'].set_color('gray') \n",
    "                ax[i,j].spines['right'].set_color('gray')\n",
    "                ax[i,j].spines['left'].set_color('gray')\n",
    "                ax[i,j].text(0.1, 0.8, elem, color='gray', fontproperties=prop, transform=ax[i,j].transAxes)\n",
    "\n",
    "        else:\n",
    "            # invalid element\n",
    "            ax[i,j].remove()\n",
    "            \n",
    "fig.savefig('images/periodic_table_pca.png', bbox_inches='tight', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92615e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
